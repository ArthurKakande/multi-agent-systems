{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BUILDING AI AGENTS WITH PLAIN PYTHON AND LLM API CALLS**"
      ],
      "metadata": {
        "id": "knq4D3YyQY06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple LLM CALL**\n",
        "\n",
        "resource https://platform.openai.com/docs/guides/tools?api-mode=responses"
      ],
      "metadata": {
        "id": "y-E3JBLAQkUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CGxGzzaAAuA8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "abjB1NMGAyrf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple prompt\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You're a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the capital city of Togo?\",\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "response = completion.choices[0].message.content\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7HoNbtFBFlH",
        "outputId": "d07461df-6499-47f2-daa8-30b0c9363afa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital city of Togo is Lom√©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pydantic**"
      ],
      "metadata": {
        "id": "qfuvpwj3Bisu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel"
      ],
      "metadata": {
        "id": "KVeVuJW_Bcrh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the response format\n",
        "class CalendarEvent(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    participants: list[str]"
      ],
      "metadata": {
        "id": "73qr0qMVBu8K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call the model\n",
        "response = client.responses.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
        "        },\n",
        "    ],\n",
        "    text_format=CalendarEvent,\n",
        ")\n",
        "\n",
        "event = response.output_parsed"
      ],
      "metadata": {
        "id": "QY0OPbnXB0Yn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "event.name\n",
        "#event.date\n",
        "#event.participants"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "il9VpiVsCDvP",
        "outputId": "4d7813d8-6310-425b-ba7c-f000aa6ae774"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Science Fair'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Tools**"
      ],
      "metadata": {
        "id": "_tKXIEqfEn75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from pydantic import Field"
      ],
      "metadata": {
        "id": "FHTTFJLBEq3P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def function\n",
        "def get_weather(latitude, longitude):\n",
        "    \"\"\"This is a publically available API that returns the weather for a given location.\"\"\"\n",
        "    response = requests.get(\n",
        "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
        "    )\n",
        "    data = response.json()\n",
        "    return data[\"current\"]"
      ],
      "metadata": {
        "id": "LV-y30jDEyRy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add the function as a tool\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"latitude\": {\"type\": \"number\"},\n",
        "                    \"longitude\": {\"type\": \"number\"},\n",
        "                },\n",
        "                \"required\": [\"latitude\", \"longitude\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "            \"strict\": True,\n",
        "        },\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "YgWrJfVAE6oI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets now specify the prompt and message for the model\n",
        "system_prompt = \"You are a helpful weather assistant.\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"},\n",
        "]\n"
      ],
      "metadata": {
        "id": "IdeCndrcFH-w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add everything to the model\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-1106\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        ")\n"
      ],
      "metadata": {
        "id": "7Orql5RKFWpT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvt5wFBcFlN1",
        "outputId": "7e75058d-fb17-434b-e2f1-bdf78715602e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-BiA8RNd67evvY2dFQmSaFVaCoXbVM',\n",
              " 'choices': [{'finish_reason': 'tool_calls',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'message': {'content': None,\n",
              "    'refusal': None,\n",
              "    'role': 'assistant',\n",
              "    'annotations': [],\n",
              "    'audio': None,\n",
              "    'function_call': None,\n",
              "    'tool_calls': [{'id': 'call_xkC6h16r6q5xaigvYihgEFFU',\n",
              "      'function': {'arguments': '{\"latitude\": 48.8566, \"longitude\": 2.3522}',\n",
              "       'name': 'get_weather'},\n",
              "      'type': 'function'}]}}],\n",
              " 'created': 1749865091,\n",
              " 'model': 'gpt-3.5-turbo-1106',\n",
              " 'object': 'chat.completion',\n",
              " 'service_tier': 'default',\n",
              " 'system_fingerprint': 'fp_982035f36f',\n",
              " 'usage': {'completion_tokens': 39,\n",
              "  'prompt_tokens': 68,\n",
              "  'total_tokens': 107,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_function(name, args):\n",
        "    if name == \"get_weather\":\n",
        "        return get_weather(**args)\n",
        "\n",
        "\n",
        "for tool_call in completion.choices[0].message.tool_calls:\n",
        "    name = tool_call.function.name\n",
        "    args = json.loads(tool_call.function.arguments)\n",
        "    messages.append(completion.choices[0].message)\n",
        "\n",
        "    result = call_function(name, args)\n",
        "    messages.append(\n",
        "        {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
        "    )\n"
      ],
      "metadata": {
        "id": "CTXQYUC7Fupr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikjDfy3sHoMl",
        "outputId": "411abb0d-b360-4531-a966-7626983e9387"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'time': '2025-06-14T01:30',\n",
              " 'interval': 900,\n",
              " 'temperature_2m': 22.0,\n",
              " 'wind_speed_10m': 1.6}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherResponse(BaseModel):\n",
        "    temperature: float = Field(\n",
        "        description=\"The current temperature in celsius for the given location.\"\n",
        "    )\n",
        "    response: str = Field(\n",
        "        description=\"A natural language response to the user's question.\"\n",
        "    )\n",
        "\n",
        "\n",
        "completion_2 = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    response_format=WeatherResponse,\n",
        ")"
      ],
      "metadata": {
        "id": "PMu6kJutF9pc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_response = completion_2.choices[0].message.parsed\n",
        "final_response.temperature\n",
        "#final_response.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V22zVmbII8a7",
        "outputId": "7e6eb516-3730-4b45-9c6e-0f0c1c37301c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chaining**"
      ],
      "metadata": {
        "id": "h7OS1u4GNP6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "# Set up logging configuration\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#model = \"gpt-4o\"\n"
      ],
      "metadata": {
        "id": "Lpo0sJlyNqjy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EventExtraction(BaseModel):\n",
        "    \"\"\"First LLM call: Extract basic event information\"\"\"\n",
        "\n",
        "    description: str = Field(description=\"Raw description of the event\")\n",
        "    is_calendar_event: bool = Field(\n",
        "        description=\"Whether this text describes a calendar event\"\n",
        "    )\n",
        "    confidence_score: float = Field(description=\"Confidence score between 0 and 1\")\n",
        "\n",
        "\n",
        "class EventDetails(BaseModel):\n",
        "    \"\"\"Second LLM call: Parse specific event details\"\"\"\n",
        "\n",
        "    name: str = Field(description=\"Name of the event\")\n",
        "    date: str = Field(\n",
        "        description=\"Date and time of the event. Use ISO 8601 to format this value.\"\n",
        "    )\n",
        "    duration_minutes: int = Field(description=\"Expected duration in minutes\")\n",
        "    participants: list[str] = Field(description=\"List of participants\")\n",
        "\n",
        "\n",
        "class EventConfirmation(BaseModel):\n",
        "    \"\"\"Third LLM call: Generate confirmation message\"\"\"\n",
        "\n",
        "    confirmation_message: str = Field(\n",
        "        description=\"Natural language confirmation message\"\n",
        "    )\n",
        "    calendar_link: Optional[str] = Field(\n",
        "        description=\"Generated calendar link if applicable\"\n",
        "    )"
      ],
      "metadata": {
        "id": "NHf6pmoCNSij"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_event_info(user_input: str) -> EventExtraction:\n",
        "    \"\"\"First LLM call to determine if input is a calendar event\"\"\"\n",
        "    logger.info(\"Starting event extraction analysis\")\n",
        "    logger.debug(f\"Input text: {user_input}\")\n",
        "\n",
        "    today = datetime.now()\n",
        "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
        "\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"{date_context} Analyze if the text describes a calendar event.\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "        response_format=EventExtraction,\n",
        "    )\n",
        "    result = completion.choices[0].message.parsed\n",
        "    logger.info(\n",
        "        f\"Extraction complete - Is calendar event: {result.is_calendar_event}, Confidence: {result.confidence_score:.2f}\"\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def parse_event_details(description: str) -> EventDetails:\n",
        "    \"\"\"Second LLM call to extract specific event details\"\"\"\n",
        "    logger.info(\"Starting event details parsing\")\n",
        "\n",
        "    today = datetime.now()\n",
        "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
        "\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"{date_context} Extract detailed event information. When dates reference 'next Tuesday' or similar relative dates, use this current date as reference.\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": description},\n",
        "        ],\n",
        "        response_format=EventDetails,\n",
        "    )\n",
        "    result = completion.choices[0].message.parsed\n",
        "    logger.info(\n",
        "        f\"Parsed event details - Name: {result.name}, Date: {result.date}, Duration: {result.duration_minutes}min\"\n",
        "    )\n",
        "    logger.debug(f\"Participants: {', '.join(result.participants)}\")\n",
        "    return result\n",
        "\n",
        "\n",
        "def generate_confirmation(event_details: EventDetails) -> EventConfirmation:\n",
        "    \"\"\"Third LLM call to generate a confirmation message\"\"\"\n",
        "    logger.info(\"Generating confirmation message\")\n",
        "\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Generate a natural confirmation message for the event. Sign of with your name; Susie\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": str(event_details.model_dump())},\n",
        "        ],\n",
        "        response_format=EventConfirmation,\n",
        "    )\n",
        "    result = completion.choices[0].message.parsed\n",
        "    logger.info(\"Confirmation message generated successfully\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "Qm0vYYnNNatO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_calendar_request(user_input: str) -> Optional[EventConfirmation]:\n",
        "    \"\"\"Main function implementing the prompt chain with gate check\"\"\"\n",
        "    logger.info(\"Processing calendar request\")\n",
        "    logger.debug(f\"Raw input: {user_input}\")\n",
        "\n",
        "    # First LLM call: Extract basic info\n",
        "    initial_extraction = extract_event_info(user_input)\n",
        "\n",
        "    # Gate check: Verify if it's a calendar event with sufficient confidence\n",
        "    if (\n",
        "        not initial_extraction.is_calendar_event\n",
        "        or initial_extraction.confidence_score < 0.7\n",
        "    ):\n",
        "        logger.warning(\n",
        "            f\"Gate check failed - is_calendar_event: {initial_extraction.is_calendar_event}, confidence: {initial_extraction.confidence_score:.2f}\"\n",
        "        )\n",
        "        return None\n",
        "\n",
        "    logger.info(\"Gate check passed, proceeding with event processing\")\n",
        "\n",
        "    # Second LLM call: Get detailed event information\n",
        "    event_details = parse_event_details(initial_extraction.description)\n",
        "\n",
        "    # Third LLM call: Generate confirmation\n",
        "    confirmation = generate_confirmation(event_details)\n",
        "\n",
        "    logger.info(\"Calendar request processing completed successfully\")\n",
        "    return confirmation\n"
      ],
      "metadata": {
        "id": "f33ui0j3NcZS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Let's schedule a 1h team meeting next Tuesday at 2pm with Alice and Bob to discuss the project roadmap.\"\n",
        "model = \"gpt-4o\"\n",
        "result = process_calendar_request(user_input)\n",
        "if result:\n",
        "    print(f\"Confirmation: {result.confirmation_message}\")\n",
        "    if result.calendar_link:\n",
        "        print(f\"Calendar Link: {result.calendar_link}\")\n",
        "else:\n",
        "    print(\"This doesn't appear to be a calendar event request.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MIxhXocNkLt",
        "outputId": "f1518cff-2448-4eb4-ed73-5bba0fe6fa45"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmation: Hi Team,\n",
            "\n",
            "This is to confirm our upcoming meeting to discuss the Project Roadmap. Please find the details below:\n",
            "\n",
            "**Date:** June 17, 2025  \n",
            "**Time:** 2:00 PM  \n",
            "**Duration:** 60 minutes\n",
            "\n",
            "Looking forward to a productive session with you both.\n",
            "\n",
            "Best regards,\n",
            "Susie\n",
            "Calendar Link: https://calendar.app-generated-invite-link.com\n"
          ]
        }
      ]
    }
  ]
}